import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression
housing_data = pd.read_csv('melbourne_housing_raw.csv')
missing_percentage = housing_data.isnull().mean() * 100
columns_to_remove = [column for column in missing_percentage.index if
missing_percentage[column] > 20 and column != 'Price']
cleaned_data = housing_data.drop(columns=columns_to_remove)
cleaned_data = cleaned_data.dropna(subset=['Price'])
features = cleaned_data.drop(columns=['Price', 'Date', 'Suburb',
'Type', 'Method', 'SellerG', 'CouncilArea', 'Regionname'])
target = cleaned_data['Price']
numeric_features = features.select_dtypes(include=[float, int])
features[numeric_features.columns] =
numeric_features.fillna(numeric_features.mean())
X_train, X_test, y_train, y_test = train_test_split(features, target,
test_size=0.2, random_state=42)
linear_model = LinearRegression()
rfe_selector = RFE(estimator=linear_model, n_features_to_select=2,
step=1)
rfe_selector.fit(X_train, y_train)
X_train_selected = rfe_selector.transform(X_train)
X_test_selected = rfe_selector.transform(X_test)
def evaluate_model(train_features, test_features, train_target,
test_target):
model = RandomForestRegressor(random_state=42)
model.fit(train_features, train_target)
predictions = model.predict(test_features)
mse = mean_squared_error(test_target, predictions)
return mse
mse_after_forward_selection = evaluate_model(X_train_selected,
X_test_selected, y_train, y_test)
print(f"Model performance after forward feature selection: MSE =
{mse_after_forward_selection:.2f}")
