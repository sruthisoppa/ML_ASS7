import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.feature_selection import VarianceThreshold
housing_data = pd.read_csv('melbourne_housing_raw.csv')
missing_percentage = housing_data.isnull().mean() * 100
columns_to_remove = [column for column in missing_percentage.index if
missing_percentage[column] > 20 and column != 'Price']
cleaned_data = housing_data.drop(columns=columns_to_remove)
cleaned_data = cleaned_data.dropna(subset=['Price'])
features = cleaned_data.drop(columns=['Price', 'Date', 'Suburb',
'Type', 'Method', 'SellerG', 'CouncilArea', 'Regionname'])
target = cleaned_data['Price']
numeric_features = features.select_dtypes(include=[float, int])
features[numeric_features.columns] =
numeric_features.fillna(numeric_features.mean())
X_train, X_test, y_train, y_test = train_test_split(features, target,
test_size=0.2, random_state=42)
variance_filter = VarianceThreshold(threshold=0.01)
X_train_low_variance = variance_filter.fit_transform(X_train)
X_test_low_variance = variance_filter.transform(X_test)
def evaluate_model(train_features, test_features, train_target,
test_target):
model = RandomForestRegressor(random_state=42)
model.fit(train_features, train_target)
predictions = model.predict(test_features)
mse = mean_squared_error(test_target, predictions)
return mse
mse_low_variance = evaluate_model(X_train_low_variance,
X_test_low_variance, y_train, y_test)
print(f"Model performance after removing low variance features: MSE =
{mse_low_variance:.2f}")
